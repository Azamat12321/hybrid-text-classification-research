{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Библеотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk  \n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "from torch import save\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1490 entries, 0 to 1489\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ArticleId  1490 non-null   int64 \n",
      " 1   Text       1490 non-null   object\n",
      " 2   Category   1490 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 35.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "base_path = \"../NLP_BBCNEWS/\"\n",
    "\n",
    "df_solution = pd.read_csv(f\"{base_path}BBC News Sample Solution.csv\")\n",
    "df_test =  pd.read_csv(f\"{base_path}BBC News Test.csv\")\n",
    "df_train = pd.read_csv(f\"{base_path}BBC News Train.csv\")\n",
    "print(df_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_dict = {\n",
    "    'business': 4,        # 'business' - 2 = business\n",
    "    'tech': 3,            # 'tech' - 3 = sci/tech\n",
    "    'politics': 1,        # 'politics' - 0 = world\n",
    "    'sport': 2,           # 'sport' - 1 = sport\n",
    "}\n",
    "\n",
    "df_train['category_id'] = df_train.Category.map(transformation_dict)\n",
    "df_train = df_train.drop(columns=[\"ArticleId\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df_train[\"category_id\"].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna().reset_index().drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_id\n",
       "2    346\n",
       "4    336\n",
       "1    274\n",
       "3    261\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_train[\"category_id\"] = df_train[\"category_id\"].astype(np.int8)\n",
    "df_train[\"category_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Category  category_id\n",
       "0  worldcom ex-boss launches defence lawyers defe...  business            4\n",
       "1  german business confidence slides german busin...  business            4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    # Удаление HTML-тегов\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Удаление ссылок\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "# Пример очистки текста\n",
    "df_train['Text'] = df_train['Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер train: 973, Размер test: 244\n"
     ]
    }
   ],
   "source": [
    "class NewsDataset(Dataset):\n",
    "  def __init__(self,df):\n",
    "    self.n_samples = len(df)\n",
    "    self.dataframe = df \n",
    "  def __getitem__(self, index):\n",
    "    row = self.dataframe.iloc[index]\n",
    "    return row['category_id'], row['Text']  \n",
    "  def __len__(self):\n",
    "    return self.n_samples\n",
    "  \n",
    "\n",
    "\n",
    "# Разделение датасета (80% - train, 20% - test)\n",
    "df_train, df_test = train_test_split(df_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Размер train: {len(df_train)}, Размер test: {len(df_test)}\")\n",
    "\n",
    "train_dataset = NewsDataset(df_train)\n",
    "test_dataset = NewsDataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import collections\n",
    "import torchtext\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = collections.Counter()\n",
    "for (label, line) in train_dataset:\n",
    "    counter.update(torchtext.data.utils.ngrams_iterator(tokenizer(line), ngrams=1))\n",
    "vocab = torchtext.vocab.Vocab(counter, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size if 21418\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "print(f\"Vocab size if {vocab_size}\")\n",
    "\n",
    "def encode(x):\n",
    "    return [vocab.stoi[s] for s in tokenizer(x)]\n",
    "\n",
    "def decode(x):\n",
    "    return [vocab.itos[i] for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padify(b):\n",
    "    v = [encode(x[1]) for x in b]\n",
    "    l = max(map(len,v))\n",
    "    return ( # tuple of two tensors - labels and features\n",
    "        torch.LongTensor([t[0]-1 for t in b]),\n",
    "        torch.stack([torch.nn.functional.pad(torch.tensor(t),(0,l-len(t)),mode='constant',value=0) for t in v])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RNNClassifierWithAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_class):\n",
    "        super(RNNClassifierWithAttention, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)  # Эмбеддинг\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)  # LSTM для обработки последовательностей\n",
    "        self.attention = nn.Linear(hidden_dim, 1)  # Слой внимания\n",
    "        self.fc = nn.Linear(hidden_dim, num_class)  # Полносвязный слой для классификации\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        x = self.embedding(x)  # Эмбеддинг\n",
    "        rnn_out, (hidden, cell) = self.rnn(x)  # Проходим через LSTM\n",
    "        # Применяем внимание\n",
    "        attention_scores = torch.tanh(self.attention(rnn_out))        # [batch_size, seq_len, 1]  \n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)    # [batch_size, seq_len, 1]\n",
    "        \n",
    "        # Получаем контекстный вектор, взвешивая выходы RNN\n",
    "        context_vector = torch.sum(attention_weights * rnn_out, dim=1)  # [batch_size, hidden_dim]\n",
    "        \n",
    "        # Применяем полносвязный слой для классификации\n",
    "        output = self.fc(context_vector)  # [batch_size, num_class]\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_10928\\1610392679.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  old_state_dict = torch.load(\"models/final/RNN + Attetion_final.pth\")\n",
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Loss: 1.1792, acc: 53.03186022610483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4, Loss: 0.4636, acc: 83.96711202466598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4, Loss: 0.2055, acc: 93.83350462487154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4, Loss: 0.1054, acc: 97.73895169578623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, collate_fn=padify, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "\n",
    "# Загрузка модели (определите вашу архитектуру перед загрузкой)\n",
    "# model = RNNClassifierWithAttention(vocab_size, 64, 32, 4).to(device)  \n",
    "model = RNNClassifierWithAttention(vocab_size, 128, 256, 4).to(device)  # vocab_size, embedding_dim, hidden_dim, num_class\n",
    "\n",
    "# old_state_dict = torch.load(\"models/rnn_attention_TORCH_91_57.pth\")\n",
    "\n",
    "old_state_dict = torch.load(\"models/final/RNN + Attetion_final.pth\")\n",
    "# Удаляем веса эмбеддингов, так как они несовместимы\n",
    "del old_state_dict['embedding.weight']\n",
    "\n",
    "# Загружаем остальные веса\n",
    "model.load_state_dict(old_state_dict, strict=False)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 4\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    epoch_loss = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        labels, text = batch\n",
    "        text, labels = text.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(text)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # Расчет accuracy\n",
    "        _, predicted = torch.max(outputs, 1)  # Получаем предсказанные классы\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "        acc = correct / total  # Текущая точность\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=epoch_loss / (progress_bar.n + 1), accuracy=acc * 100)\n",
    "    final_acc = correct / total * 100\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss / len(train_loader):.4f}, acc: {final_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       1.00      0.60      0.75        70\n",
      "      Sports       0.62      0.98      0.76        59\n",
      "    Business       0.85      0.77      0.81        44\n",
      "    Sci/Tech       0.90      0.86      0.88        71\n",
      "\n",
      "    accuracy                           0.80       244\n",
      "   macro avg       0.84      0.80      0.80       244\n",
      "weighted avg       0.85      0.80      0.80       244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, collate_fn=padify, shuffle=True)\n",
    "\n",
    "model.eval()  # Устанавливаем модель в режим оценки\n",
    "model.to(device)\n",
    "\n",
    "classes = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "\n",
    "# Получаем прогнозы и истинные метки\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        labels, text = batch\n",
    "        text, labels = text.to(device), labels.to(device)\n",
    "\n",
    "        # Получаем выходы модели\n",
    "        outputs = model(text)\n",
    "        predicted_classes = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        all_preds.extend(predicted_classes.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Создаем отчет классификации\n",
    "report = classification_report(all_labels, all_preds, target_names=classes)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# epoch = 6, batch_size=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "       World       0.84      0.87      0.85        70\n",
    "      Sports       0.85      0.95      0.90        59\n",
    "    Business       0.85      0.91      0.88        44\n",
    "    Sci/Tech       0.95      0.77      0.85        71\n",
    "\n",
    "    accuracy                           0.87       244\n",
    "   macro avg       0.87      0.88      0.87       244\n",
    "weighted avg       0.87      0.87      0.87       244"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "       World       0.92      0.80      0.85        70\n",
    "      Sports       0.90      0.92      0.91        59\n",
    "    Business       0.84      0.84      0.84        44\n",
    "    Sci/Tech       0.86      0.96      0.91        71\n",
    "\n",
    "    accuracy                           0.88       244\n",
    "   macro avg       0.88      0.88      0.88       244\n",
    "weighted avg       0.88      0.88      0.88       244"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "       World       0.97      0.84      0.90        70\n",
    "      Sports       0.95      0.98      0.97        59\n",
    "    Business       0.85      0.89      0.87        44\n",
    "    Sci/Tech       0.87      0.93      0.90        71\n",
    "\n",
    "    accuracy                           0.91       244\n",
    "   macro avg       0.91      0.91      0.91       244\n",
    "weighted avg       0.91      0.91      0.91       244"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "       World       0.97      0.86      0.91        70\n",
    "      Sports       0.98      0.98      0.98        59\n",
    "    Business       0.88      0.98      0.92        44\n",
    "    Sci/Tech       0.89      0.93      0.91        71\n",
    "\n",
    "    accuracy                           0.93       244\n",
    "   macro avg       0.93      0.94      0.93       244\n",
    "weighted avg       0.93      0.93      0.93       244"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size = 32\\  \n",
    "epoch = 4\\\n",
    "model = RNNClassifierWithAttention(vocab_size, 128, 256, 4).to(device) \\\n",
    "old_state_dict = torch.load(\"models/final/RNN + Attetion_final.pth\")\n",
    "\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       World       0.97      0.86      0.91        70\n",
    "      Sports       0.97      0.98      0.97        59\n",
    "    Business       0.88      0.98      0.92        44\n",
    "    Sci/Tech       0.90      0.93      0.92        71\n",
    "\n",
    "    accuracy                           0.93       244\n",
    "    macro avg       0.93      0.94     0.93       244\n",
    "    weighted avg    0.93      0.93     0.93       244"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
