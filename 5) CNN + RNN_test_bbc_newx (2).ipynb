{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "from torch import save\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk  \n",
    "from nltk.util import ngrams\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "\n",
    "# Проверка наличия GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1490 entries, 0 to 1489\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ArticleId  1490 non-null   int64 \n",
      " 1   Text       1490 non-null   object\n",
      " 2   Category   1490 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 35.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "base_path = \"../NLP_BBCNEWS/\"\n",
    "\n",
    "df_solution = pd.read_csv(f\"{base_path}BBC News Sample Solution.csv\")\n",
    "df_test =  pd.read_csv(f\"{base_path}BBC News Test.csv\")\n",
    "df_train = pd.read_csv(f\"{base_path}BBC News Train.csv\")\n",
    "print(df_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_id\n",
       "2    346\n",
       "4    336\n",
       "1    274\n",
       "3    261\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformation_dict = {\n",
    "    'business': 4,        # 'business' - 2 = business\n",
    "    'tech': 3,            # 'tech' - 3 = sci/tech\n",
    "    'politics': 1,        # 'politics' - 0 = world\n",
    "    'sport': 2,           # 'sport' - 1 = sport\n",
    "}\n",
    "\n",
    "df_train['category_id'] = df_train.Category.map(transformation_dict)\n",
    "df_train = df_train.drop(columns=[\"ArticleId\"])\n",
    "df_train = df_train.dropna().reset_index().drop(columns=[\"index\"])\n",
    "\n",
    "df_train[\"category_id\"] = df_train[\"category_id\"].astype(np.int8)\n",
    "df_train[\"category_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    # Удаление HTML-тегов\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Удаление ссылок\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "# Пример очистки текста\n",
    "df_train['Text'] = df_train['Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер train: 973, Размер test: 244\n"
     ]
    }
   ],
   "source": [
    "class NewsDataset(Dataset):\n",
    "  def __init__(self,df):\n",
    "    self.n_samples = len(df)\n",
    "    self.dataframe = df \n",
    "  def __getitem__(self, index):\n",
    "    row = self.dataframe.iloc[index]\n",
    "    return row['category_id'], row['Text']  \n",
    "  def __len__(self):\n",
    "    return self.n_samples\n",
    "  \n",
    "\n",
    "\n",
    "# Разделение датасета (80% - train, 20% - test)\n",
    "df_train, df_test = train_test_split(df_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Размер train: {len(df_train)}, Размер test: {len(df_test)}\")\n",
    "\n",
    "train_dataset = NewsDataset(df_train)\n",
    "test_dataset = NewsDataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import collections\n",
    "import torchtext\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = collections.Counter()\n",
    "for (label, line) in train_dataset:\n",
    "    counter.update(torchtext.data.utils.ngrams_iterator(tokenizer(line), ngrams=1))\n",
    "vocab = torchtext.vocab.Vocab(counter, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size if 21418\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "print(f\"Vocab size if {vocab_size}\")\n",
    "\n",
    "def encode(x):\n",
    "    return [vocab.stoi[s] for s in tokenizer(x)]\n",
    "\n",
    "def decode(x):\n",
    "    return [vocab.itos[i] for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padify(b):\n",
    "    v = [encode(x[1]) for x in b]\n",
    "    l = max(map(len,v))\n",
    "    return ( # tuple of two tensors - labels and features\n",
    "        torch.LongTensor([t[0]-1 for t in b]),\n",
    "        torch.stack([torch.nn.functional.pad(torch.tensor(t),(0,l-len(t)),mode='constant',value=0) for t in v])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNNRNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, cnn_out_channels, kernel_size, hidden_dim, num_classes):\n",
    "        super(CNNRNNClassifier, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)  # Слой эмбеддинга\n",
    "        self.conv1d = nn.Conv1d(in_channels=embedding_dim, \n",
    "                               out_channels=cnn_out_channels, \n",
    "                               kernel_size=kernel_size, \n",
    "                               padding=kernel_size // 2)  # 1D свертка\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=cnn_out_channels, hidden_size=hidden_dim, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)  # Полносвязный слой\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # Преобразование в эмбеддинги [batch_size, seq_len, embedding_dim]\n",
    "        x = x.permute(0, 2, 1)  # Перестановка для Conv1d [batch_size, embedding_dim, seq_len]\n",
    "        \n",
    "        x = F.relu(self.conv1d(x))  # Применение свертки и активации ReLU\n",
    "        x = x.permute(0, 2, 1)  # Обратно в форму [batch_size, seq_len, cnn_out_channels]\n",
    "        \n",
    "        rnn_out, (hidden, cell) = self.rnn(x)  # Передача в LSTM\n",
    "        output = self.fc(hidden[-1])  # Используем последний скрытый слой\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_10796\\4110146056.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  old_state_dict = torch.load(\"models/final/CNN+RNN_final.pth\")\n",
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 1.4390, acc: 33.19630010277492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Loss: 1.2593, acc: 45.83761562178829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: 1.1799, acc: 50.668036998972255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Loss: 1.0856, acc: 53.340184994861254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Loss: 1.0636, acc: 53.23741007194245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, collate_fn=padify, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "\n",
    "# Загрузка модели (определите вашу архитектуру перед загрузкой)\n",
    "model = CNNRNNClassifier(vocab_size, embedding_dim=300, cnn_out_channels=128, kernel_size=5, hidden_dim=256, num_classes=4).to(device)\n",
    "\n",
    "old_state_dict = torch.load(\"models/final/CNN+RNN_final.pth\")\n",
    "# Удаляем веса эмбеддингов, так как они несовместимы\n",
    "del old_state_dict['embedding.weight']\n",
    "\n",
    "# Загружаем остальные веса\n",
    "model.load_state_dict(old_state_dict, strict=False)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    epoch_loss = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        labels, text = batch\n",
    "        text, labels = text.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(text)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # Расчет accuracy\n",
    "        _, predicted = torch.max(outputs, 1)  # Получаем предсказанные классы\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "        acc = correct / total  # Текущая точность\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=epoch_loss / (progress_bar.n + 1), accuracy=acc * 100)\n",
    "    final_acc = correct / total * 100\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss / len(train_loader):.4f}, acc: {final_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       0.39      0.81      0.52        70\n",
      "      Sports       0.67      0.93      0.78        59\n",
      "    Business       0.36      0.11      0.17        44\n",
      "    Sci/Tech       0.00      0.00      0.00        71\n",
      "\n",
      "    accuracy                           0.48       244\n",
      "   macro avg       0.35      0.47      0.37       244\n",
      "weighted avg       0.34      0.48      0.37       244\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s:\\PYTHON_VS\\DataScience\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "s:\\PYTHON_VS\\DataScience\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "s:\\PYTHON_VS\\DataScience\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, collate_fn=padify, shuffle=True)\n",
    "\n",
    "model.eval()  # Устанавливаем модель в режим оценки\n",
    "model.to(device)\n",
    "\n",
    "classes = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "\n",
    "# Получаем прогнозы и истинные метки\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        labels, text = batch\n",
    "        text, labels = text.to(device), labels.to(device)\n",
    "\n",
    "        # Получаем выходы модели\n",
    "        outputs = model(text)\n",
    "        predicted_classes = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        all_preds.extend(predicted_classes.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Создаем отчет классификации\n",
    "report = classification_report(all_labels, all_preds, target_names=classes)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#        World       0.94      0.91      0.92      1900\n",
    "#       Sports       0.95      0.98      0.96      1900\n",
    "#     Business       0.90      0.85      0.88      1900\n",
    "#     Sci/Tech       0.86      0.91      0.89      1900\n",
    "\n",
    "#     accuracy                           0.91      7600\n",
    "#    macro avg       0.91      0.91      0.91      7600\n",
    "# weighted avg       0.91      0.91      0.91      7600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#        World       0.93      0.90      0.92      1900\n",
    "#       Sports       0.96      0.97      0.97      1900\n",
    "#     Business       0.85      0.91      0.88      1900\n",
    "#     Sci/Tech       0.90      0.86      0.88      1900\n",
    "\n",
    "#     accuracy                           0.91      7600\n",
    "#    macro avg       0.91      0.91      0.91      7600\n",
    "# weighted avg       0.91      0.91      0.91      7600\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
